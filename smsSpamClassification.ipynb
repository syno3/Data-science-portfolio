{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smsSpamClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKADN+1bk3356POeIuZlAU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzfZFy2VE80K"
      },
      "source": [
        "### importing the required modules\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tbx_idxGI6k"
      },
      "source": [
        "# get data files\n",
        "#loading the data\n",
        "\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TWK7-tqJ_yD"
      },
      "source": [
        "## converting to dataFrame and Preprocessing\n",
        "\n",
        "train_df = pd.read_csv(train_file_path, sep='\\t', names=['Classification', 'Text'])\n",
        "test_df = pd.read_csv(test_file_path, sep='\\t', names=['Classification', 'Text'])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWFp2uuwLj92"
      },
      "source": [
        "## Mapping the data\n",
        "\n",
        "x_train = train_df.drop('Classification', axis=1)\n",
        "y_train = train_df.drop('Text', axis=1).astype('category')\n",
        "\n",
        "x_test = test_df.drop('Classification', axis=1)\n",
        "y_test = test_df.drop('Text', axis=1).astype('category')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR6hM9VZNx7F"
      },
      "source": [
        "### encoding the spam and ham into [0,1]\n",
        "\n",
        "y_train =  y_train['Classification'].cat.codes\n",
        "y_test = y_test['Classification'].cat.codes"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40EYJXnROivK"
      },
      "source": [
        "## iterate over column (text) and encode raw text\n",
        "VOCAB_SIZE = 1000\n",
        "for i in x_train:\n",
        "  encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "      max_tokens=VOCAB_SIZE)\n",
        "  encoder.adapt(np.array(x_train[i]))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNrPVVVTVMu8"
      },
      "source": [
        "for j in x_test:\n",
        "  encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "      max_tokens=VOCAB_SIZE)\n",
        "  encoder.adapt(np.array(x_test[j]))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apf0yHvvUzdg"
      },
      "source": [
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiKK0o6-V6tR"
      },
      "source": [
        "### encode the text into indexes (y_train)\n",
        "for i in x_train:\n",
        "  data_train = x_train[i]\n",
        "  encoded_x_train = encoder(data_train)[:3].numpy()\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv1fQcBX0rC"
      },
      "source": [
        "### encode the text into indexes (y_train)\n",
        "for i in x_test:\n",
        "  data_test = x_test[i]\n",
        "  encoded_x_test = encoder(data_test)[:3].numpy()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBbsyt8IYG6M",
        "outputId": "cd41e8ca-5586-401d-a55d-f798786852b8"
      },
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", data_train[n])\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_x_train[n]]))\n",
        "  print()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  ahhhh...just woken up!had a bad dream about u tho,so i dont like u right now :) i didnt know anything about comedy night but i guess im up for it.\n",
            "Round-trip:  [UNK] [UNK] [UNK] a bad [UNK] about u [UNK] i dont like u right now i didnt know anything about [UNK] night but i guess im up for it                                                                                                                                              \n",
            "\n",
            "Original:  you can never do nothing\n",
            "Round-trip:  you can never do nothing                                                                                                                                                                      \n",
            "\n",
            "Original:  now u sound like manky scouse boy steve,like! i is travelling on da bus home.wot has u inmind 4 recreation dis eve?\n",
            "Round-trip:  now u [UNK] like [UNK] [UNK] boy [UNK] i is [UNK] on da bus [UNK] has u [UNK] 4 [UNK] dis [UNK]                                                                                                                                                     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJoopI7IY7qc"
      },
      "source": [
        "#### creat the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtIq-j3JZUWz",
        "outputId": "2eb1260e-7675-4d41-c216-7f9f112c78de"
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = (\"how are you doing today?\")\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.01117236]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm61BhNzZldL",
        "outputId": "21f683d0-fc93-41bd-c912-a6b42afade17"
      },
      "source": [
        "# predict on a sample text with padding\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.01117236]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-DVIPWIZvhG"
      },
      "source": [
        "###compiling the model\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV4FMjBniXKa",
        "outputId": "3ccdc11f-d7ae-40ef-88ad-de4378fa1941"
      },
      "source": [
        "model.fit(x=x_train,y=y_train,epochs=10,validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "131/131 [==============================] - 3s 20ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.1213 - val_accuracy: 0.9849\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 3s 22ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1245 - val_accuracy: 0.9849\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 3s 20ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1254 - val_accuracy: 0.9849\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 2s 19ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1299 - val_accuracy: 0.9849\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 2s 19ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1303 - val_accuracy: 0.9849\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 3s 19ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1335 - val_accuracy: 0.9849\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 2s 19ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.1334 - val_accuracy: 0.9849\n",
            "Epoch 8/10\n",
            "131/131 [==============================] - 2s 19ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.1348 - val_accuracy: 0.9849\n",
            "Epoch 9/10\n",
            "131/131 [==============================] - 3s 20ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.1764 - val_accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "131/131 [==============================] - 3s 21ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.1508 - val_accuracy: 0.9734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcefc3d7810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXXjsGbylJ4T",
        "outputId": "1a471e90-4809-4076-90e5-81d36ca25e80"
      },
      "source": [
        "predictions = model.predict_classes(x_test)\n",
        "print(x_test[7:8])\n",
        "print(\"probability\",y_test[7:8])\n",
        "print(\"prediction was\",predictions[7])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               Text\n",
            "7  yes. it's all innocent fun. o:-)\n",
            "probability 7    0\n",
            "dtype: int8\n",
            "prediction was [0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}